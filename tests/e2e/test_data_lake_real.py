"""
Data Lake çœŸå®ç«¯åˆ°ç«¯æµ‹è¯•
=========================

æµ‹è¯•åœºæ™¯ï¼š
1. åˆ›å»ºä¸¤å° Lightsail å®ä¾‹ï¼š
   - Collector å®ä¾‹ï¼šè¿è¡Œ data collector æ”¶é›† CEX tick æ•°æ®
   - Data Lake å®ä¾‹ï¼šè¿è¡Œ data lake è¿›è¡Œæ•°æ®åŒæ­¥
   
2. å®Œæ•´å·¥ä½œæµï¼š
   - åœ¨ Collector å®ä¾‹ä¸Šéƒ¨ç½² data collector
   - ç­‰å¾… 1 åˆ†é’Ÿæ”¶é›† CEX tick diff æ•°æ®
   - åœ¨ Data Lake å®ä¾‹ä¸Šé…ç½® data lake
   - æ‰§è¡Œ rsync ä» Collector åŒæ­¥æ•°æ®åˆ° Data Lake
   - éªŒè¯æ•°æ®åŒæ­¥æˆåŠŸ
   - æ£€æŸ¥ checkpoint å’Œç»Ÿè®¡ä¿¡æ¯
   - æ¸…ç†èµ„æº

âš ï¸ è­¦å‘Š: æ­¤æµ‹è¯•ä¼šåˆ›å»ºçœŸå®çš„ AWS èµ„æºå¹¶äº§ç”Ÿè´¹ç”¨ï¼
é¢„è®¡è´¹ç”¨: ~$0.02-0.05 (2å° nano_3_0 å®ä¾‹è¿è¡Œ 10-15 åˆ†é’Ÿ)

è¿è¡Œæ–¹å¼ï¼š
pytest tests/e2e/test_data_lake_real.py -v -s --run-e2e
æˆ–ä½¿ç”¨è„šæœ¬ï¼š
bash tests/e2e/scripts/run_data_lake.sh
"""

import pytest
import time
import os
import json
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from deployers.data_collector import DataCollectorDeployer
from providers.aws.lightsail_manager import LightsailManager


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def run_ssh_command(
    host: str,
    command: str,
    ssh_key_path: str,
    ssh_port: int = 22,
    ssh_user: str = 'ubuntu',
    timeout: int = 30
) -> dict:
    """æ‰§è¡Œ SSH å‘½ä»¤"""
    cmd = [
        'ssh', '-i', os.path.expanduser(ssh_key_path), '-p', str(ssh_port),
        '-o', 'StrictHostKeyChecking=no',
        '-o', 'UserKnownHostsFile=/dev/null',
        '-o', 'ConnectTimeout=10',
        f'{ssh_user}@{host}',
        command
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, timeout=timeout, text=True)
        return {
            'success': result.returncode == 0,
            'stdout': result.stdout,
            'stderr': result.stderr,
            'returncode': result.returncode
        }
    except subprocess.TimeoutExpired:
        return {
            'success': False,
            'stdout': '',
            'stderr': f'Command timed out after {timeout} seconds',
            'returncode': -1
        }
    except Exception as e:
        return {
            'success': False,
            'stdout': '',
            'stderr': str(e),
            'returncode': -1
        }


def print_test_header(title: str):
    """æ‰“å°æµ‹è¯•æ ‡é¢˜"""
    print(f"\n{'='*80}")
    print(f"  {title}")
    print(f"{'='*80}\n")


def print_step(step_num: int, total_steps: int, description: str):
    """æ‰“å°æµ‹è¯•æ­¥éª¤"""
    print(f"\n[Step {step_num}/{total_steps}] {description}")
    print("-" * 80)


def print_info(message: str):
    """æ‰“å°ä¿¡æ¯"""
    print(f"â„¹ï¸  {message}")


def print_success(message: str):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(f"âœ… {message}")


def print_error(message: str):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(f"âŒ {message}")


# ============================================================================
# Fixtures
# ============================================================================

@pytest.fixture(scope="module")
def run_e2e(request):
    """æ£€æŸ¥æ˜¯å¦è¿è¡Œ E2E æµ‹è¯•"""
    if not request.config.getoption("--run-e2e", default=False):
        pytest.skip("E2E tests are skipped by default. Use --run-e2e to run them.")


@pytest.fixture(scope="module")
def test_config(run_e2e):
    """æµ‹è¯•é…ç½®"""
    # SSH å¯†é’¥é…ç½®
    ssh_key_candidates = [
        ('lightsail-test-key', '~/.ssh/lightsail-test-key.pem'),
        ('LightsailDefaultKey-ap-northeast-1', '~/.ssh/LightsailDefaultKey-ap-northeast-1.pem'),
        ('id_rsa', '~/.ssh/id_rsa'),
    ]
    
    ssh_key_name = None
    ssh_key_path = None
    
    for key_name, key_path in ssh_key_candidates:
        expanded_path = os.path.expanduser(key_path)
        if os.path.exists(expanded_path):
            ssh_key_name = key_name
            ssh_key_path = expanded_path
            print(f"\nâœ… æ‰¾åˆ° SSH å¯†é’¥: {key_name} -> {key_path}")
            break
    
    if not ssh_key_path:
        raise FileNotFoundError(
            "æœªæ‰¾åˆ°å¯ç”¨çš„ SSH å¯†é’¥æ–‡ä»¶ã€‚è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€å­˜åœ¨:\n" +
            "\n".join([f"  - {path}" for _, path in ssh_key_candidates])
        )
    
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
    timestamp = int(time.time())
    
    return {
        # AWS é…ç½®
        'region': os.getenv('TEST_AWS_REGION', 'ap-northeast-1'),
        'bundle_id': 'small_3_0',  # ä½¿ç”¨ small è§„æ ¼ (2GB RAM)ï¼Œnano å†…å­˜ä¸è¶³
        'ssh_key_name': ssh_key_name,
        'ssh_key_path': ssh_key_path,
        
        # å®ä¾‹é…ç½®
        'collector_instance_name': f'collector-dl-e2e-{timestamp}',
        'data_lake_instance_name': f'datalake-dl-e2e-{timestamp}',
        
        # æ•°æ®é‡‡é›†å™¨é…ç½®
        'exchange': 'gateio',
        'pairs': ['VIRTUAL-USDT'],  # åªæµ‹è¯•ä¸€ä¸ªäº¤æ˜“å¯¹
        'collect_duration_seconds': 180,  # å¢åŠ åˆ° 180 ç§’ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿæ—¶é—´æ”¶é›†æ•°æ®
        'collector_github_repo': 'https://github.com/FireNirva/hummingbot-quants-lab.git',
        'collector_github_branch': 'main',
        
        # Data Lake é…ç½®
        'data_lake_root': '/home/ubuntu/data_lake',
        'collector_data_root': '/data/orderbook_ticks',  # quants-lab é»˜è®¤è¾“å‡ºç›®å½•
        'data_lake_github_repo': 'https://github.com/FireNirva/quants-infra.git',
        'data_lake_github_branch': 'main',
        'quants_infra_dir': 'quants-infra',  # Data Lake GitHub ä»“åº“å…‹éš†åçš„ç›®å½•å
        
        # Ansible é…ç½®
        'ansible_dir': os.path.join(project_root, 'ansible'),
        
        # è¶…æ—¶é…ç½®
        'instance_ready_timeout': 300,
        'collector_start_timeout': 180,
        'data_collection_timeout': 240,  # å¢åŠ è¶…æ—¶ä»¥åŒ¹é…æ–°çš„æ”¶é›†æ—¶é—´
        
        # æ¸…ç†é…ç½®
        'cleanup_on_failure': False,  # å¤±è´¥æ—¶ä¸æ¸…ç†ï¼Œä¾¿äºè°ƒè¯•
        'cleanup_on_success': True,   # æˆåŠŸåæ¸…ç†
    }


@pytest.fixture(scope="module")
def lightsail_manager(test_config):
    """Lightsail ç®¡ç†å™¨"""
    config = {
        'provider': 'aws',
        'region': test_config['region'],
        'aws_access_key_id': os.getenv('AWS_ACCESS_KEY_ID'),
        'aws_secret_access_key': os.getenv('AWS_SECRET_ACCESS_KEY')
    }
    return LightsailManager(config)


@pytest.fixture(scope="module")
def collector_instance(test_config, lightsail_manager):
    """åˆ›å»ºå¹¶é…ç½® Collector å®ä¾‹"""
    print_test_header("å‡†å¤‡ Data Collector å®ä¾‹")
    
    instance_name = test_config['collector_instance_name']
    print(f"å®ä¾‹åç§°: {instance_name}")
    print(f"åŒºåŸŸ: {test_config['region']}")
    print(f"è§„æ ¼: {test_config['bundle_id']}")
    
    # åˆ›å»ºå®ä¾‹
    print_step(1, 4, "åˆ›å»º Lightsail å®ä¾‹")
    instance_config = {
        'name': instance_name,
        'bundle_id': test_config['bundle_id'],
        'blueprint_id': 'ubuntu_22_04',
        'key_pair_name': test_config['ssh_key_name'],
        'availability_zone': f"{test_config['region']}a"
    }
    
    try:
        instance_info = lightsail_manager.create_instance(instance_config)
        print_success("å®ä¾‹åˆ›å»ºè¯·æ±‚å·²æäº¤")
    except Exception as e:
        pytest.fail(f"å®ä¾‹åˆ›å»ºå¤±è´¥: {e}")
    
    # ç­‰å¾…å®ä¾‹è¿è¡Œ
    print_step(2, 4, "ç­‰å¾…å®ä¾‹å¯åŠ¨")
    if not lightsail_manager.wait_for_instance_running(
        instance_name, 
        timeout=test_config['instance_ready_timeout']
    ):
        pytest.fail("å®ä¾‹å¯åŠ¨è¶…æ—¶")
    print_success("å®ä¾‹å·²å¯åŠ¨")
    
    # é…ç½®å®‰å…¨ç»„
    print_step(3, 4, "é…ç½®å®‰å…¨ç»„")
    ports = [
        {'protocol': 'tcp', 'from_port': 22, 'to_port': 22},      # SSH
        {'protocol': 'tcp', 'from_port': 6677, 'to_port': 6677},  # å®‰å…¨ SSH
    ]
    lightsail_manager.open_instance_ports(instance_name, ports)
    print_success("å®‰å…¨ç»„é…ç½®å®Œæˆ")
    
    # è·å–å®ä¾‹ä¿¡æ¯
    print_step(4, 4, "è·å–å®ä¾‹ä¿¡æ¯")
    time.sleep(30)  # ç­‰å¾…ç½‘ç»œé…ç½®
    instance_info = lightsail_manager.get_instance_info(instance_name)
    public_ip = instance_info['public_ip']
    print_success(f"å…¬ç½‘ IP: {public_ip}")
    
    # ç­‰å¾… SSH å¯ç”¨
    print("ç­‰å¾… SSH å¯ç”¨...")
    max_retries = 20
    for i in range(max_retries):
        result = run_ssh_command(
            public_ip, 
            'echo "test"', 
            test_config['ssh_key_path']
        )
        if result['success']:
            print_success("SSH è¿æ¥æˆåŠŸ")
            break
        time.sleep(10)
    else:
        pytest.fail("SSH è¿æ¥è¶…æ—¶")
    
    instance_data = {
        'name': instance_name,
        'public_ip': public_ip,
        'instance_info': instance_info
    }
    
    yield instance_data
    
    # æ¸…ç†
    if test_config['cleanup_on_success']:
        print(f"\næ¸…ç† Collector å®ä¾‹: {instance_name}")
        try:
            lightsail_manager.destroy_instance(instance_name, force=True)
            print_success(f"å®ä¾‹ {instance_name} å·²åˆ é™¤")
        except Exception as e:
            print_error(f"æ¸…ç†å¤±è´¥: {e}")


@pytest.fixture(scope="module")
def data_lake_instance(test_config, lightsail_manager):
    """åˆ›å»ºå¹¶é…ç½® Data Lake å®ä¾‹"""
    print_test_header("å‡†å¤‡ Data Lake å®ä¾‹")
    
    instance_name = test_config['data_lake_instance_name']
    print(f"å®ä¾‹åç§°: {instance_name}")
    
    # åˆ›å»ºå®ä¾‹
    print_step(1, 4, "åˆ›å»º Lightsail å®ä¾‹")
    instance_config = {
        'name': instance_name,
        'bundle_id': test_config['bundle_id'],
        'blueprint_id': 'ubuntu_22_04',
        'key_pair_name': test_config['ssh_key_name'],
        'availability_zone': f"{test_config['region']}a"
    }
    
    try:
        instance_info = lightsail_manager.create_instance(instance_config)
        print_success("å®ä¾‹åˆ›å»ºè¯·æ±‚å·²æäº¤")
    except Exception as e:
        pytest.fail(f"å®ä¾‹åˆ›å»ºå¤±è´¥: {e}")
    
    # ç­‰å¾…å®ä¾‹è¿è¡Œ
    print_step(2, 4, "ç­‰å¾…å®ä¾‹å¯åŠ¨")
    if not lightsail_manager.wait_for_instance_running(
        instance_name, 
        timeout=test_config['instance_ready_timeout']
    ):
        pytest.fail("å®ä¾‹å¯åŠ¨è¶…æ—¶")
    print_success("å®ä¾‹å·²å¯åŠ¨")
    
    # é…ç½®å®‰å…¨ç»„
    print_step(3, 4, "é…ç½®å®‰å…¨ç»„")
    ports = [
        {'protocol': 'tcp', 'from_port': 22, 'to_port': 22},      # SSH
        {'protocol': 'tcp', 'from_port': 6677, 'to_port': 6677},  # å®‰å…¨ SSH
    ]
    lightsail_manager.open_instance_ports(instance_name, ports)
    print_success("å®‰å…¨ç»„é…ç½®å®Œæˆ")
    
    # è·å–å®ä¾‹ä¿¡æ¯
    print_step(4, 4, "è·å–å®ä¾‹ä¿¡æ¯")
    time.sleep(30)
    instance_info = lightsail_manager.get_instance_info(instance_name)
    public_ip = instance_info['public_ip']
    print_success(f"å…¬ç½‘ IP: {public_ip}")
    
    # ç­‰å¾… SSH å¯ç”¨
    print("ç­‰å¾… SSH å¯ç”¨...")
    max_retries = 20
    for i in range(max_retries):
        result = run_ssh_command(
            public_ip, 
            'echo "test"', 
            test_config['ssh_key_path']
        )
        if result['success']:
            print_success("SSH è¿æ¥æˆåŠŸ")
            break
        time.sleep(10)
    else:
        pytest.fail("SSH è¿æ¥è¶…æ—¶")
    
    instance_data = {
        'name': instance_name,
        'public_ip': public_ip,
        'instance_info': instance_info
    }
    
    yield instance_data
    
    # æ¸…ç†
    if test_config['cleanup_on_success']:
        print(f"\næ¸…ç† Data Lake å®ä¾‹: {instance_name}")
        try:
            lightsail_manager.destroy_instance(instance_name, force=True)
            print_success(f"å®ä¾‹ {instance_name} å·²åˆ é™¤")
        except Exception as e:
            print_error(f"æ¸…ç†å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯•ç±»
# ============================================================================

@pytest.mark.e2e
class TestDataLakeRealE2E:
    """Data Lake çœŸå®ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    def test_01_deploy_data_collector(self, test_config, collector_instance):
        """
        æµ‹è¯• 1: éƒ¨ç½² Data Collector
        
        æ­¥éª¤ï¼š
        1. åœ¨ Collector å®ä¾‹ä¸Šéƒ¨ç½² data collector
        2. å¯åŠ¨æ•°æ®é‡‡é›†
        3. ç­‰å¾…æ”¶é›†æ•°æ®
        """
        print_test_header("æµ‹è¯• 1: éƒ¨ç½² Data Collector")
        
        collector_ip = collector_instance['public_ip']
        
        print_step(1, 3, "éƒ¨ç½² Data Collector")
        
        deployer_config = {
            'ansible_dir': test_config['ansible_dir'],
            'ssh_key_path': test_config['ssh_key_path'],
            'ssh_port': 22,
            'ssh_user': 'ubuntu',
            'vpn_ip': collector_ip,  # ä½¿ç”¨å…¬ç½‘ IP ä½œä¸º VPN IPï¼ˆæµ‹è¯•åœºæ™¯ï¼‰
            'github_repo': test_config['collector_github_repo'],
            'github_branch': test_config['collector_github_branch'],
            'exchange': test_config['exchange'],
            'pairs': ','.join(test_config['pairs']),
            'depth_limit': 20,
            'snapshot_interval': 100,
            'output_dir': test_config['collector_data_root']
        }
        
        deployer = DataCollectorDeployer(deployer_config)
        
        # éƒ¨ç½²
        print("å¼€å§‹éƒ¨ç½²...")
        result = deployer.deploy([collector_ip], vpn_ip=collector_ip)
        assert result is True, "Data Collector éƒ¨ç½²å¤±è´¥"
        print_success("Data Collector éƒ¨ç½²æˆåŠŸ")
        
        print_step(2, 3, "å¯åŠ¨æ•°æ®é‡‡é›†")
        result = deployer.start(collector_ip)
        assert result is True, "Data Collector å¯åŠ¨å¤±è´¥"
        print_success("Data Collector å·²å¯åŠ¨")
        
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦åœ¨è¿è¡Œ
        print("\næ£€æŸ¥ Data Collector è¿›ç¨‹...")
        check_process_cmd = "ps aux | grep '[c]li.py serve' || echo 'No process found'"
        process_result = run_ssh_command(
            collector_ip,
            check_process_cmd,
            test_config['ssh_key_path']
        )
        if process_result['success']:
            print(f"è¿›ç¨‹çŠ¶æ€:\n{process_result['stdout']}")
        
        # æ£€æŸ¥ç½‘ç»œè¿æ¥
        print("\næ£€æŸ¥ç½‘ç»œè¿æ¥...")
        network_cmd = "netstat -tn | grep -E 'ESTABLISHED.*:443|ESTABLISHED.*:9443' || echo 'No WebSocket connections found'"
        network_result = run_ssh_command(
            collector_ip,
            network_cmd,
            test_config['ssh_key_path']
        )
        if network_result['success']:
            print(f"WebSocket è¿æ¥:\n{network_result['stdout']}")
        
        # æŸ¥çœ‹é…ç½®æ–‡ä»¶
        print("\næŸ¥çœ‹ç”Ÿæˆçš„é…ç½®æ–‡ä»¶...")
        config_cmd = "cat /opt/quants-lab/config/orderbook_tick_gateio.yml"
        config_result = run_ssh_command(
            collector_ip,
            config_cmd,
            test_config['ssh_key_path']
        )
        if config_result['success']:
            print(f"é…ç½®æ–‡ä»¶å†…å®¹:\n{config_result['stdout']}")
        
        # æŸ¥çœ‹ metrics è¾“å‡º
        print("\næŸ¥çœ‹ Metrics è¾“å‡º...")
        metrics_cmd = "curl -s http://127.0.0.1:8000/metrics | grep -E 'orderbook_collector_(ticks_written|files_written|connection_status|messages_received)'"
        metrics_result = run_ssh_command(
            collector_ip,
            metrics_cmd,
            test_config['ssh_key_path']
        )
        if metrics_result['success']:
            print(f"Metrics å…³é”®æŒ‡æ ‡:\n{metrics_result['stdout']}")
        
        # æŸ¥çœ‹åº”ç”¨æ—¥å¿—ï¼ˆstdout/stderrï¼‰
        print("\næŸ¥çœ‹åº”ç”¨æ—¥å¿—æ–‡ä»¶...")
        app_log_cmd = """
        echo '=== STDOUT Log (last 100 lines) ===' && \
        if [ -f /var/log/quants-lab/gateio-collector.log ]; then
            tail -100 /var/log/quants-lab/gateio-collector.log
        else
            echo 'STDOUT log not found'
        fi && \
        echo '' && \
        echo '=== STDERR Log (last 100 lines) ===' && \
        if [ -f /var/log/quants-lab/gateio-collector-error.log ]; then
            tail -100 /var/log/quants-lab/gateio-collector-error.log
        else
            echo 'STDERR log not found'
        fi && \
        echo '' && \
        echo '=== Systemd Journal (last 50 lines) ===' && \
        journalctl -u quants-lab-gateio-collector -n 50 --no-pager
        """
        app_log_result = run_ssh_command(
            collector_ip,
            app_log_cmd,
            test_config['ssh_key_path'],
            timeout=30
        )
        if app_log_result['success']:
            print(f"å®Œæ•´åº”ç”¨æ—¥å¿—:\n{app_log_result['stdout']}")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡å’Œé…ç½®ï¼ŒéªŒè¯é…ç½®æ–‡ä»¶
        print("\næ£€æŸ¥ç¯å¢ƒå˜é‡ã€é…ç½®å’ŒéªŒè¯é…ç½®æ–‡ä»¶...")
        env_check_cmd = """
        echo '=== Environment Variables ===' && \
        sudo cat /etc/systemd/system/quants-lab-gateio-collector.service | grep -E 'Environment=' && \
        echo '' && \
        echo '=== Config File ===' && \
        cat /opt/quants-lab/config/orderbook_tick_gateio.yml && \
        echo '' && \
        echo '=== Validate Config (should show no errors) ===' && \
        cd /opt/quants-lab && \
        /opt/miniconda3/bin/conda run --no-capture-output -n quants-lab python cli.py validate-config config/orderbook_tick_gateio.yml 2>&1 && \
        echo '' && \
        echo '=== List Tasks ===' && \
        /opt/miniconda3/bin/conda run --no-capture-output -n quants-lab python cli.py list-tasks --config config/orderbook_tick_gateio.yml 2>&1
        """
        env_result = run_ssh_command(
            collector_ip,
            env_check_cmd,
            test_config['ssh_key_path'],
            timeout=30
        )
        if env_result['success']:
            print(f"ç¯å¢ƒå’Œé…ç½®ä¿¡æ¯:\n{env_result['stdout']}")
        
        print_step(3, 3, f"ç­‰å¾…æ”¶é›†æ•°æ® ({test_config['collect_duration_seconds']} ç§’)")
        print("ğŸ“ æ³¨æ„ï¼šç°åœ¨ä½¿ç”¨ run-tasks å‘½ä»¤ï¼Œä¼šå®é™…è¿è¡Œæ•°æ®é‡‡é›†ä»»åŠ¡")
        
        # ç­‰å¾… 30 ç§’åé¦–æ¬¡æ£€æŸ¥
        wait_time = 30
        time.sleep(wait_time)
        print(f"\né¦–æ¬¡æ£€æŸ¥æ•°æ®é‡‡é›†çŠ¶æ€ï¼ˆ{wait_time}ç§’åï¼‰...")
        
        # æ£€æŸ¥ metrics æ˜¯å¦æœ‰å®é™…æ•°æ®
        status_metrics_cmd = "curl -s http://127.0.0.1:8000/metrics | grep -E 'orderbook_collector_(connection_status|messages_received_total|ticks_written_total)' | grep -v '^#'"
        status_result = run_ssh_command(collector_ip, status_metrics_cmd, test_config['ssh_key_path'])
        if status_result['success']:
            status_output = status_result['stdout'].strip()
            if status_output:
                print(f"å½“å‰ Metrics çŠ¶æ€:\n{status_output}")
            else:
                print("âš ï¸  Metrics ä¸­æ²¡æœ‰å®é™…æ•°å€¼")
                # å¦‚æœæ²¡æœ‰ metricsï¼Œæ£€æŸ¥åº”ç”¨æ˜¯å¦çœŸçš„åœ¨è¿è¡Œä»»åŠ¡
                print("\næ£€æŸ¥åº”ç”¨æ˜¯å¦çœŸçš„åœ¨è¿è¡Œä»»åŠ¡...")
                check_cmd = """
                echo '=== Process status ===' && \
                ps aux | grep '[c]li.py' && \
                echo '' && \
                echo '=== Recent application logs (last 30 lines) ===' && \
                journalctl -u quants-lab-gateio-collector --since '30 seconds ago' --no-pager | tail -30
                """
                check_result = run_ssh_command(collector_ip, check_cmd, test_config['ssh_key_path'])
                if check_result['success']:
                    print(f"è¯Šæ–­ä¿¡æ¯:\n{check_result['stdout']}")
        
        # ç»§ç»­ç­‰å¾…å‰©ä½™æ—¶é—´
        remaining_time = test_config['collect_duration_seconds'] - wait_time
        print(f"\nç»§ç»­ç­‰å¾… {remaining_time} ç§’...")
        time.sleep(remaining_time)
        
        # æœ€åå†æ£€æŸ¥ä¸€æ¬¡çŠ¶æ€
        print("\næœ€ç»ˆçŠ¶æ€æ£€æŸ¥...")
        final_status_result = run_ssh_command(collector_ip, status_metrics_cmd, test_config['ssh_key_path'])
        if final_status_result['success']:
            final_output = final_status_result['stdout'].strip()
            if final_output:
                print(f"æœ€ç»ˆ Metrics çŠ¶æ€:\n{final_output}")
        
        print_success("æ•°æ®æ”¶é›†å®Œæˆ")
        
        # éªŒè¯æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼ˆæŸ¥æ‰¾ parquet æˆ– csv æ–‡ä»¶ï¼‰
        # å¢åŠ é‡è¯•æœºåˆ¶ï¼Œå› ä¸ºæ–‡ä»¶å¯èƒ½åœ¨åˆšå¥½æ”¶é›†å®Œæˆåæ‰å†™å…¥
        print("\néªŒè¯æ•°æ®æ–‡ä»¶...")
        check_cmd = f"find {test_config['collector_data_root']} -type f \\( -name '*.parquet' -o -name '*.csv' \\) 2>/dev/null | head -10"
        
        # æœ€å¤šé‡è¯•3æ¬¡ï¼Œæ¯æ¬¡ç­‰å¾…10ç§’
        max_retries = 3
        files = ""
        for attempt in range(max_retries):
            result = run_ssh_command(
                collector_ip,
                check_cmd,
                test_config['ssh_key_path']
            )
            if result['success']:
                files = result['stdout'].strip()
                if files:
                    break
            if attempt < max_retries - 1:
                print(f"å°è¯• {attempt + 1}/{max_retries}: æœªæ‰¾åˆ°æ–‡ä»¶ï¼Œç­‰å¾…10ç§’åé‡è¯•...")
                time.sleep(10)
        
        if files:
                print(f"æ‰¾åˆ°æ•°æ®æ–‡ä»¶ (parquet/csv):\n{files}")
                
                # ç»Ÿè®¡æ–‡ä»¶æ•°é‡å’Œå¤§å°
                count_cmd = f"find {test_config['collector_data_root']} -type f | wc -l && du -sh {test_config['collector_data_root']}"
                count_result = run_ssh_command(
                    collector_ip,
                    count_cmd,
                    test_config['ssh_key_path']
                )
                if count_result['success']:
                    print(f"ç»Ÿè®¡ä¿¡æ¯:\n{count_result['stdout']}")
                
                print_success("æ•°æ®æ–‡ä»¶éªŒè¯é€šè¿‡")
        else:
            # æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ‰“å°æ›´å¤šè¯Šæ–­ä¿¡æ¯
            print_error("æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼ˆparquet/csvï¼‰")
            
            # æ£€æŸ¥ç›®å½•å†…å®¹
            ls_cmd = f"ls -lhR {test_config['collector_data_root']}"
            ls_result = run_ssh_command(collector_ip, ls_cmd, test_config['ssh_key_path'])
            print(f"ç›®å½•å†…å®¹:\n{ls_result['stdout']}")
            
            # å†æ¬¡æ£€æŸ¥è¿›ç¨‹å’Œæ—¥å¿—
            ps_cmd = "ps aux | grep '[c]li.py'"
            ps_result = run_ssh_command(collector_ip, ps_cmd, test_config['ssh_key_path'])
            print(f"è¿›ç¨‹çŠ¶æ€:\n{ps_result['stdout']}")
            
            # æŸ¥çœ‹æœåŠ¡çŠ¶æ€
            status_cmd = "systemctl status quants-lab-gateio-collector --no-pager"
            status_result = run_ssh_command(collector_ip, status_cmd, test_config['ssh_key_path'])
            print(f"æœåŠ¡çŠ¶æ€:\n{status_result['stdout']}")
            
            # å°è¯•æ‰‹åŠ¨è§¦å‘ä»»åŠ¡çœ‹æ˜¯å¦æœ‰é”™è¯¯
            print("\nâš ï¸  å°è¯•æ‰‹åŠ¨è§¦å‘ä»»åŠ¡ä»¥è¯Šæ–­é—®é¢˜...")
            trigger_cmd = """
            cd /opt/quants-lab && \
            timeout 60 /opt/miniconda3/bin/conda run --no-capture-output -n quants-lab \
                python cli.py trigger-task --task orderbook_tick_gateio \
                --config config/orderbook_tick_gateio.yml \
                --timeout 50 2>&1 || echo "Trigger failed or timed out"
            """
            trigger_result = run_ssh_command(collector_ip, trigger_cmd, test_config['ssh_key_path'], timeout=70)
            if trigger_result['success']:
                print(f"æ‰‹åŠ¨è§¦å‘ç»“æœ:\n{trigger_result['stdout']}")
                # å†æ¬¡æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ç”Ÿæˆ
                files_result = run_ssh_command(
                    collector_ip,
                    f"find {test_config['collector_data_root']} -type f 2>/dev/null | head -5",
                    test_config['ssh_key_path']
                )
                if files_result['success'] and files_result['stdout'].strip():
                    print(f"æ‰‹åŠ¨è§¦å‘åå‘ç°æ–‡ä»¶:\n{files_result['stdout']}")
            
            pytest.fail("Data Collector æ²¡æœ‰æ”¶é›†åˆ°æ•°æ®æ–‡ä»¶")
        
        print("\nâœ… æµ‹è¯• 1 é€šè¿‡\n")
    
    def test_02_setup_data_lake(self, test_config, data_lake_instance, collector_instance):
        """
        æµ‹è¯• 2: é…ç½® Data Lake
        
        æ­¥éª¤ï¼š
        1. å®‰è£…ç³»ç»Ÿä¾èµ– (rsync, git, python3)
        2. å…‹éš† GitHub ä»“åº“
        3. å®‰è£… quants-infra
        4. åˆ›å»º Data Lake é…ç½®æ–‡ä»¶å¹¶éªŒè¯
        """
        print_test_header("æµ‹è¯• 2: é…ç½® Data Lake")
        
        data_lake_ip = data_lake_instance['public_ip']
        collector_ip = collector_instance['public_ip']
        
        print_step(1, 4, "å®‰è£…ç³»ç»Ÿä¾èµ–")
        
        install_cmd = """
        sudo apt-get update && \
        sudo apt-get install -y rsync git python3-pip python3-venv && \
        echo "System dependencies installed"
        """
        
        result = run_ssh_command(
            data_lake_ip,
            install_cmd,
            test_config['ssh_key_path'],
            timeout=300
        )
        
        if result['success']:
            print_success("ç³»ç»Ÿä¾èµ–å®‰è£…æˆåŠŸ")
        else:
            pytest.fail(f"ç³»ç»Ÿä¾èµ–å®‰è£…å¤±è´¥: {result['stderr']}")
        
        print_step(2, 4, "å…‹éš† GitHub ä»“åº“")
        
        clone_cmd = f"""
        cd ~ && \
        rm -rf {test_config['quants_infra_dir']} && \
        git clone {test_config['data_lake_github_repo']} && \
        cd {test_config['quants_infra_dir']} && \
        git checkout {test_config['data_lake_github_branch']} && \
        echo "Repository cloned successfully"
        """
        
        result = run_ssh_command(
            data_lake_ip,
            clone_cmd,
            test_config['ssh_key_path'],
            timeout=120
        )
        
        if result['success']:
            print_success(f"GitHub ä»“åº“å…‹éš†æˆåŠŸ ({test_config['data_lake_github_branch']} åˆ†æ”¯)")
        else:
            pytest.fail(f"GitHub ä»“åº“å…‹éš†å¤±è´¥: {result['stderr']}")
        
        print_step(3, 4, "å®‰è£… quants-infra")
        
        setup_cmd = f"""
        cd ~/{test_config['quants_infra_dir']} && \
        pip3 install --user -r requirements.txt && \
        pip3 install --user -e . && \
        export PATH=$PATH:/home/ubuntu/.local/bin && \
        /home/ubuntu/.local/bin/quants-infra --version && \
        echo "quants-infra installed successfully"
        """
        
        result = run_ssh_command(
            data_lake_ip,
            setup_cmd,
            test_config['ssh_key_path'],
            timeout=180
        )
        
        if result['success']:
            print("å®‰è£…è¾“å‡ºï¼š")
            print(result['stdout'])
            print_success("quants-infra å®‰è£…æˆåŠŸ")
        else:
            pytest.fail(f"quants-infra å®‰è£…å¤±è´¥: {result['stderr']}")
        
        print_step(4, 4, "é…ç½® Data Lake ç¯å¢ƒ")
        
        # åˆ›å»ºé…ç½®æ–‡ä»¶
        config_content = f"""data_lake:
  root_dir: {test_config['data_lake_root']}
  profiles:
    cex_ticks:
      enabled: true
      source:
        type: ssh
        host: {collector_ip}
        port: 22
        user: ubuntu
        ssh_key: ~/.ssh/collector_key.pem
        remote_root: {test_config['collector_data_root']}
      local_subdir: data
      retention_days: 7
      rsync_args: "-az --partial --inplace"
"""
        
        config_cmd = f"""
        mkdir -p ~/{test_config['quants_infra_dir']}/config && \
        mkdir -p {test_config['data_lake_root']}/checkpoints && \
        mkdir -p {test_config['data_lake_root']}/data && \
        cat > ~/{test_config['quants_infra_dir']}/config/data_lake.yml << 'EOF'
{config_content}EOF
        echo "Data Lake configuration created"
        """
        
        result = run_ssh_command(
            data_lake_ip,
            config_cmd,
            test_config['ssh_key_path']
        )
        
        if result['success']:
            print_success("Data Lake é…ç½®åˆ›å»ºæˆåŠŸ")
        else:
            pytest.fail(f"é…ç½®åˆ›å»ºå¤±è´¥: {result['stderr']}")
        
        # å¤åˆ¶ SSH å¯†é’¥åˆ° Data Lake å®ä¾‹ï¼ˆç”¨äºè®¿é—® Collectorï¼‰
        print("é…ç½® SSH è®¿é—®...")
        scp_cmd = [
            'scp',
            '-i', test_config['ssh_key_path'],
            '-o', 'StrictHostKeyChecking=no',
            '-o', 'UserKnownHostsFile=/dev/null',
            test_config['ssh_key_path'],
            f"ubuntu@{data_lake_ip}:~/.ssh/collector_key.pem"
        ]
        
        result = subprocess.run(scp_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            # è®¾ç½®å¯†é’¥æƒé™
            chmod_cmd = "chmod 600 ~/.ssh/collector_key.pem"
            run_ssh_command(data_lake_ip, chmod_cmd, test_config['ssh_key_path'])
            print_success("SSH å¯†é’¥é…ç½®æˆåŠŸ")
        else:
            pytest.fail(f"SSH å¯†é’¥å¤åˆ¶å¤±è´¥: {result.stderr}")
        
        # éªŒè¯é…ç½®
        print("\néªŒè¯ Data Lake é…ç½®...")
        validate_cmd = f"cd ~/{test_config['quants_infra_dir']} && /home/ubuntu/.local/bin/quants-infra data-lake validate --config config/data_lake.yml"
        result = run_ssh_command(
            data_lake_ip,
            validate_cmd,
            test_config['ssh_key_path']
        )
        
        if result['success']:
            print(result['stdout'])
            print_success("é…ç½®éªŒè¯é€šè¿‡")
        else:
            pytest.fail(f"é…ç½®éªŒè¯å¤±è´¥: {result['stderr']}")
        
        print("\nâœ… æµ‹è¯• 2 é€šè¿‡\n")
    
    def test_03_sync_data(self, test_config, data_lake_instance, collector_instance):
        """
        æµ‹è¯• 3: åŒæ­¥æ•°æ®
        
        æ­¥éª¤ï¼š
        1. ä½¿ç”¨ quants-infra data-lake sync å‘½ä»¤åŒæ­¥æ•°æ®
        2. æŸ¥çœ‹ Data Lake ç»Ÿè®¡ä¿¡æ¯
        3. éªŒè¯æ•°æ®æ–‡ä»¶å’Œå®Œæ•´æ€§
        """
        print_test_header("æµ‹è¯• 3: åŒæ­¥æ•°æ®")
        
        data_lake_ip = data_lake_instance['public_ip']
        collector_ip = collector_instance['public_ip']
        
        print_step(1, 3, "ä½¿ç”¨ quants-infra æ‰§è¡Œæ•°æ®åŒæ­¥")
        
        # ä½¿ç”¨ quants-infra data-lake sync å‘½ä»¤
        sync_cmd = f"""
        cd ~/{test_config['quants_infra_dir']} && \
        /home/ubuntu/.local/bin/quants-infra data-lake sync cex_ticks --config config/data_lake.yml
        """
        
        print("æ‰§è¡Œ Data Lake åŒæ­¥å‘½ä»¤...")
        print(f"ä» Collector ({collector_ip}) åŒæ­¥åˆ° Data Lake ({data_lake_ip})")
        result = run_ssh_command(
            data_lake_ip,
            sync_cmd,
            test_config['ssh_key_path'],
            timeout=300
        )
        
        if result['success']:
            print("åŒæ­¥è¾“å‡ºï¼š")
            print(result['stdout'])
            print_success("æ•°æ®åŒæ­¥æˆåŠŸ")
        else:
            pytest.fail(f"æ•°æ®åŒæ­¥å¤±è´¥: {result['stderr']}")
        
        print_step(2, 3, "æŸ¥çœ‹ Data Lake ç»Ÿè®¡ä¿¡æ¯")
        
        stats_cmd = f"""
        cd ~/{test_config['quants_infra_dir']} && \
        /home/ubuntu/.local/bin/quants-infra data-lake stats cex_ticks --config config/data_lake.yml
        """
        
        result = run_ssh_command(
            data_lake_ip,
            stats_cmd,
            test_config['ssh_key_path']
        )
        
        if result['success']:
            print("Data Lake ç»Ÿè®¡ä¿¡æ¯ï¼š")
            print(result['stdout'])
            print_success("ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ")
        else:
            print(f"è­¦å‘Š: ç»Ÿè®¡ä¿¡æ¯è·å–å¤±è´¥: {result['stderr']}")
        
        # åŒæ—¶ä½¿ç”¨ ls å‘½ä»¤éªŒè¯æ•°æ®æ–‡ä»¶
        check_cmd = f"ls -lhR {test_config['data_lake_root']}/data/ | head -50"
        result = run_ssh_command(
            data_lake_ip,
            check_cmd,
            test_config['ssh_key_path']
        )
        
        if result['success']:
            print("\nåŒæ­¥åçš„æ•°æ®æ–‡ä»¶ï¼š")
            print(result['stdout'])
            assert len(result['stdout'].strip()) > 0, "åŒæ­¥åæ²¡æœ‰æ•°æ®æ–‡ä»¶"
            print_success("æ•°æ®æ–‡ä»¶éªŒè¯é€šè¿‡")
        else:
            pytest.fail(f"æ— æ³•éªŒè¯æ•°æ®æ–‡ä»¶: {result['stderr']}")
        
        print_step(3, 3, "ç»Ÿè®¡æ•°æ®")
        
        stats_cmd = f"""
        echo "æ–‡ä»¶æ•°é‡:" && find {test_config['data_lake_root']}/data/ -type f | wc -l && \
        echo "æ€»å¤§å°:" && du -sh {test_config['data_lake_root']}/data/
        """
        
        result = run_ssh_command(
            data_lake_ip,
            stats_cmd,
            test_config['ssh_key_path']
        )
        
        if result['success']:
            print("æ•°æ®ç»Ÿè®¡ï¼š")
            print(result['stdout'])
            print_success("æ•°æ®ç»Ÿè®¡å®Œæˆ")
        else:
            print_error(f"ç»Ÿè®¡å¤±è´¥: {result['stderr']}")
        
        print("\nâœ… æµ‹è¯• 3 é€šè¿‡\n")
    
    def test_04_verify_data_integrity(self, test_config, data_lake_instance, collector_instance):
        """
        æµ‹è¯• 4: éªŒè¯æ•°æ®å®Œæ•´æ€§
        
        æ­¥éª¤ï¼š
        1. æ¯”è¾ƒæºå’Œç›®æ ‡çš„æ–‡ä»¶æ•°é‡
        2. éªŒè¯æ–‡ä»¶å†…å®¹ä¸€è‡´æ€§
        """
        print_test_header("æµ‹è¯• 4: éªŒè¯æ•°æ®å®Œæ•´æ€§")
        
        data_lake_ip = data_lake_instance['public_ip']
        collector_ip = collector_instance['public_ip']
        
        print_step(1, 2, "æ¯”è¾ƒæ–‡ä»¶æ•°é‡")
        
        # è·å– Collector çš„æ–‡ä»¶æ•°é‡
        count_cmd = f"find {test_config['collector_data_root']} -type f | wc -l"
        collector_result = run_ssh_command(
            collector_ip,
            count_cmd,
            test_config['ssh_key_path']
        )
        
        # è·å– Data Lake çš„æ–‡ä»¶æ•°é‡
        data_lake_result = run_ssh_command(
            data_lake_ip,
            f"find {test_config['data_lake_root']}/data/ -type f | wc -l",
            test_config['ssh_key_path']
        )
        
        if collector_result['success'] and data_lake_result['success']:
            collector_count = int(collector_result['stdout'].strip())
            data_lake_count = int(data_lake_result['stdout'].strip())
            
            print(f"Collector æ–‡ä»¶æ•°: {collector_count}")
            print(f"Data Lake æ–‡ä»¶æ•°: {data_lake_count}")
            
            # å…è®¸å°‘é‡å·®å¼‚ï¼ˆå¯èƒ½æœ‰æ–°æ–‡ä»¶åœ¨åŒæ­¥åç”Ÿæˆï¼‰
            assert data_lake_count > 0, "Data Lake æ²¡æœ‰æ–‡ä»¶"
            assert data_lake_count >= collector_count * 0.9, "åŒæ­¥çš„æ–‡ä»¶æ•°é‡æ˜æ˜¾å°‘äºæº"
            print_success("æ–‡ä»¶æ•°é‡éªŒè¯é€šè¿‡")
        else:
            pytest.fail("æ— æ³•æ¯”è¾ƒæ–‡ä»¶æ•°é‡")
        
        print_step(2, 2, "éªŒè¯æ–‡ä»¶åˆ—è¡¨")
        
        # è·å–æ–‡ä»¶åˆ—è¡¨å¹¶æ¯”è¾ƒ
        list_cmd = f"find {test_config['collector_data_root']} -type f -name '*.csv' | head -5"
        result = run_ssh_command(
            collector_ip,
            list_cmd,
            test_config['ssh_key_path']
        )
        
        if result['success'] and result['stdout'].strip():
            print("ç¤ºä¾‹æ–‡ä»¶ï¼š")
            print(result['stdout'])
            print_success("æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        else:
            print_error("æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨")
        
        print("\nâœ… æµ‹è¯• 4 é€šè¿‡\n")


# ============================================================================
# è¿è¡Œé…ç½®
# ============================================================================

def pytest_addoption(parser):
    """æ·»åŠ  pytest å‘½ä»¤è¡Œé€‰é¡¹"""
    parser.addoption(
        "--run-e2e",
        action="store_true",
        default=False,
        help="è¿è¡Œ E2E æµ‹è¯•ï¼ˆé»˜è®¤è·³è¿‡ï¼‰"
    )


if __name__ == '__main__':
    pytest.main([__file__, '-v', '-s', '--run-e2e'])

